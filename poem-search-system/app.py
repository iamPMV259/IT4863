import streamlit as st
from elasticsearch import Elasticsearch
from sentence_transformers import SentenceTransformer

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="HUST Poem Search", layout="wide")

# K·∫øt n·ªëi ES (D√πng 127.0.0.1 nh∆∞ b√™n indexer)
es = Elasticsearch("http://127.0.0.1:9200", request_timeout=30)
INDEX_NAME = "poems_hust_project"

@st.cache_resource
def load_model():
    return SentenceTransformer('keepitreal/vietnamese-sbert')

model = load_model()

# --- HEADER & SIDEBAR ---
st.title("üîé H·ªá th·ªëng T√¨m ki·∫øm Th∆° (Hybrid Search)")
st.caption(f"Tr·∫°ng th√°i k·∫øt n·ªëi ES: {'üü¢ Online' if es.ping() else 'üî¥ Offline'}")

with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh T√¨m ki·∫øm")
    search_mode = st.radio(
        "Ch·ªçn thu·∫≠t to√°n:",
        ("M√¥ h√¨nh X√°c su·∫•t (BM25)", "M√¥ h√¨nh Vector (Semantic)")
    )
    
    st.divider()
    st.info("""
    **Gi·∫£i th√≠ch:**
    1. **BM25 (Best Matching):** T√¨m d·ª±a tr√™n t·ª´ kh√≥a ch√≠nh x√°c v√† t·∫ßn su·∫•t xu·∫•t hi·ªán.
    2. **Semantic Search:** T√¨m d·ª±a tr√™n √Ω nghƒ©a, ng·ªØ c·∫£nh vector (AI).
    """)

# --- MAIN UI ---
query = st.text_input("Nh·∫≠p t·ª´ kh√≥a, c√¢u th∆° ho·∫∑c t√¢m tr·∫°ng:", placeholder="V√≠ d·ª•: N·ªói nh·ªõ m√πa thu...")

if st.button("T√¨m ki·∫øm", type="primary") or query:
    if not query.strip():
        st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung t√¨m ki·∫øm!")
    else:
        results = []
        try:
            if search_mode == "M√¥ h√¨nh X√°c su·∫•t (BM25)":
                # --- LOGIC BM25 ---
                body = {
                    "query": {
                        "multi_match": {
                            "query": query,
                            "fields": ["poem_title^3", "poem_content_text"], # Title quan tr·ªçng x3
                            "fuzziness": "AUTO" # Ch·∫•p nh·∫≠n sai ch√≠nh t·∫£ nh·∫π
                        }
                    },
                    "size": 5
                }
                resp = es.search(index=INDEX_NAME, body=body)
                results = resp['hits']['hits']
                
            else:
                # --- LOGIC VECTOR ---
                query_vector = model.encode(query).tolist()
                body = {
                    "knn": {
                        "field": "poem_vector",
                        "query_vector": query_vector,
                        "k": 5,
                        "num_candidates": 100
                    },
                    "_source": ["poem_title", "author", "poem_content_text", "the_tho", "thoi_ky"]
                }
                resp = es.search(index=INDEX_NAME, body=body)
                results = resp['hits']['hits']

            # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
            st.subheader(f"K·∫øt qu·∫£ ({len(results)} b√†i ph√π h·ª£p):")
            
            if not results:
                st.info("Kh√¥ng t√¨m th·∫•y b√†i th∆° n√†o. Th·ª≠ t·ª´ kh√≥a kh√°c xem sao!")
            
            for hit in results:
                score = hit['_score']
                src = hit['_source']
                
                with st.expander(f"üìñ {src['poem_title']} - {src['author']} (Score: {score:.2f})", expanded=True):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        # Hi·ªÉn th·ªã n·ªôi dung (c·∫Øt 6 d√≤ng ƒë·∫ßu)
                        content_lines = src['poem_content_text'].split('\n')
                        preview = "\n".join(content_lines[:6])
                        st.text(preview + ("\n..." if len(content_lines) > 6 else ""))
                    
                    with col2:
                        st.badge(src.get('the_tho', 'N/A'))
                        st.caption(f"Th·ªùi k·ª≥: {src.get('thoi_ky', 'N/A')}")
                        st.caption(f"ID: {hit['_id']}")
                        
        except Exception as e:
            st.error(f"L·ªói khi t√¨m ki·∫øm: {e}")